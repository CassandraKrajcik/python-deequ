{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Storing Computed Metrics in a MetricsRepository\n",
    "\n",
    "PyDeequ allows us to persist the metrics we computed on dataframes in a so-called MetricsRepository. In the following example, we showcase how to store metrics in a filesystem and query them later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, Row, DataFrame\n",
    "import json\n",
    "import pandas as pd\n",
    "import sagemaker_pyspark\n",
    "\n",
    "import pydeequ\n",
    "\n",
    "classpath = \":\".join(sagemaker_pyspark.classpath_jars())\n",
    "\n",
    "spark = (SparkSession\n",
    "    .builder\n",
    "    .config(\"spark.driver.extraClassPath\", classpath)\n",
    "    .config(\"spark.jars.packages\", pydeequ.deequ_maven_coord)\n",
    "    .config(\"spark.jars.excludes\", pydeequ.f2j_maven_coord)\n",
    "    .getOrCreate())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will be using the Amazon Product Reviews dataset\n",
    "\n",
    "Specifically the Electronics and Books subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- marketplace: string (nullable = true)\n",
      " |-- customer_id: string (nullable = true)\n",
      " |-- review_id: string (nullable = true)\n",
      " |-- product_id: string (nullable = true)\n",
      " |-- product_parent: string (nullable = true)\n",
      " |-- product_title: string (nullable = true)\n",
      " |-- star_rating: integer (nullable = true)\n",
      " |-- helpful_votes: integer (nullable = true)\n",
      " |-- total_votes: integer (nullable = true)\n",
      " |-- vine: string (nullable = true)\n",
      " |-- verified_purchase: string (nullable = true)\n",
      " |-- review_headline: string (nullable = true)\n",
      " |-- review_body: string (nullable = true)\n",
      " |-- review_date: date (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- marketplace: string (nullable = true)\n",
      " |-- customer_id: string (nullable = true)\n",
      " |-- review_id: string (nullable = true)\n",
      " |-- product_id: string (nullable = true)\n",
      " |-- product_parent: string (nullable = true)\n",
      " |-- product_title: string (nullable = true)\n",
      " |-- star_rating: integer (nullable = true)\n",
      " |-- helpful_votes: integer (nullable = true)\n",
      " |-- total_votes: integer (nullable = true)\n",
      " |-- vine: string (nullable = true)\n",
      " |-- verified_purchase: string (nullable = true)\n",
      " |-- review_headline: string (nullable = true)\n",
      " |-- review_body: string (nullable = true)\n",
      " |-- review_date: date (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      "\n",
      "None None\n"
     ]
    }
   ],
   "source": [
    "df_electronics = spark.read.parquet(\"s3a://amazon-reviews-pds/parquet/product_category=Electronics/\")\n",
    "\n",
    "df_books = spark.read.parquet(\"s3a://amazon-reviews-pds/parquet/product_category=Books/\")\n",
    "\n",
    "print(df_electronics.printSchema(), df_books.printSchema())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Metrics Repository\n",
    "\n",
    "We will be demoing with the `FileSystemMetricsRepository` class, but you can optionally use `InMemoryMetricsRepository` the exact same way without creating a `metrics_file` like so: `repository = InMemoryMetricsRepository(spark)`. \n",
    "\n",
    "**Metrics Repository allows us to store the metrics in json format on the local disk (note that it also supports HDFS and S3).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metrics_file path: /tmp/1595457441222-0/metrics.json\n"
     ]
    }
   ],
   "source": [
    "from pydeequ.repository import *\n",
    "\n",
    "metrics_file = FileSystemMetricsRepository.helper_metrics_file(spark, 'metrics.json')\n",
    "print(f'metrics_file path: {metrics_file}')\n",
    "repository = FileSystemMetricsRepository(spark, metrics_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Each set of metrics that we computed needs be indexed by a so-called `ResultKey`, which contains a timestamp and supports arbitrary tags in the form of key-value pairs. Let's setup one for this example:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_tags = {'tag': 'electronics'}\n",
    "resultKey = ResultKey(spark, ResultKey.current_milli_time(), key_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will be building off the Analyzers basic tutorial ... including Metrics Repository into it! \n",
    "\n",
    "Now we can run checks or analyzers on our data as usual. However, we make deequ store the resulting metrics for the checks in our repository by adding the `useRepository` and `saveOrAppendResult` methods to our invocation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+-------------------+--------------------+\n",
      "|     entity|            instance|               name|               value|\n",
      "+-----------+--------------------+-------------------+--------------------+\n",
      "|     Column|           review_id|       Completeness|                 1.0|\n",
      "|     Column|           review_id|ApproxCountDistinct|           3010972.0|\n",
      "|Mutlicolumn|total_votes,star_...|        Correlation|-0.03451097996538765|\n",
      "|    Dataset|                   *|               Size|           3120938.0|\n",
      "|     Column|         star_rating|               Mean|   4.036143941340712|\n",
      "|     Column|     top star_rating|         Compliance|  0.7494070692849394|\n",
      "|Mutlicolumn|total_votes,helpf...|        Correlation|  0.9936463809903863|\n",
      "+-----------+--------------------+-------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pydeequ.analyzers import *\n",
    "\n",
    "analysisResult = AnalysisRunner(spark) \\\n",
    "                    .onData(df_electronics) \\\n",
    "                    .addAnalyzer(Size()) \\\n",
    "                    .addAnalyzer(Completeness(\"review_id\")) \\\n",
    "                    .addAnalyzer(ApproxCountDistinct(\"review_id\")) \\\n",
    "                    .addAnalyzer(Mean(\"star_rating\")) \\\n",
    "                    .addAnalyzer(Compliance(\"top star_rating\", \"star_rating >= 4.0\")) \\\n",
    "                    .addAnalyzer(Correlation(\"total_votes\", \"star_rating\")) \\\n",
    "                    .addAnalyzer(Correlation(\"total_votes\", \"helpful_votes\")) \\\n",
    "                    .useRepository(repository) \\\n",
    "                    .saveOrAppendResult(resultKey) \\\n",
    "                    .run()\n",
    "                    \n",
    "analysisResult_df = AnalyzerContext.successMetricsAsDataFrame(spark, analysisResult)\n",
    "analysisResult_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can load it back now from Metrics Repository \n",
    "\n",
    "PyDeequ now executes the verification as usual and additionally stores the metrics under our specified key. Afterwards, we can retrieve the metrics from the repository in different ways. We can for example directly load the metric for a particular analyzer stored under our result key as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+-------------------+--------------------+-------------+-----------+\n",
      "|     entity|            instance|               name|               value| dataset_date|        tag|\n",
      "+-----------+--------------------+-------------------+--------------------+-------------+-----------+\n",
      "|     Column|           review_id|       Completeness|                 1.0|1595457441235|electronics|\n",
      "|     Column|           review_id|ApproxCountDistinct|           3010972.0|1595457441235|electronics|\n",
      "|Mutlicolumn|total_votes,star_...|        Correlation|-0.03451097996538765|1595457441235|electronics|\n",
      "|    Dataset|                   *|               Size|           3120938.0|1595457441235|electronics|\n",
      "|     Column|         star_rating|               Mean|   4.036143941340712|1595457441235|electronics|\n",
      "|     Column|     top star_rating|         Compliance|  0.7494070692849394|1595457441235|electronics|\n",
      "|Mutlicolumn|total_votes,helpf...|        Correlation|  0.9936463809903863|1595457441235|electronics|\n",
      "+-----------+--------------------+-------------------+--------------------+-------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "analysisResult_metRep = repository.load() \\\n",
    "                            .before(ResultKey.current_milli_time()) \\\n",
    "                            .getSuccessMetricsAsDataFrame()\n",
    "\n",
    "analysisResult_metRep.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### But that's not very interesting... Let's run another Analysis on the books dataset! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+-------------------+--------------------+\n",
      "|     entity|            instance|               name|               value|\n",
      "+-----------+--------------------+-------------------+--------------------+\n",
      "|     Column|           review_id|       Completeness|                 1.0|\n",
      "|     Column|           review_id|ApproxCountDistinct|          2.005151E7|\n",
      "|Mutlicolumn|total_votes,star_...|        Correlation|-0.13092955077624202|\n",
      "|    Dataset|                   *|               Size|          2.072616E7|\n",
      "|     Column|         star_rating|               Mean|   4.340540167594962|\n",
      "|     Column|     top star_rating|         Compliance|  0.8302768095971468|\n",
      "|Mutlicolumn|total_votes,helpf...|        Correlation|  0.9613189372804929|\n",
      "+-----------+--------------------+-------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "key_tags_2 = {'tag': 'books'}\n",
    "resultKey_2 = ResultKey(spark, ResultKey.current_milli_time(), key_tags_2)\n",
    "\n",
    "analysisResult_2 = AnalysisRunner(spark) \\\n",
    "                    .onData(df_books) \\\n",
    "                    .addAnalyzer(Size()) \\\n",
    "                    .addAnalyzer(Completeness(\"review_id\")) \\\n",
    "                    .addAnalyzer(ApproxCountDistinct(\"review_id\")) \\\n",
    "                    .addAnalyzer(Mean(\"star_rating\")) \\\n",
    "                    .addAnalyzer(Compliance(\"top star_rating\", \"star_rating >= 4.0\")) \\\n",
    "                    .addAnalyzer(Correlation(\"total_votes\", \"star_rating\")) \\\n",
    "                    .addAnalyzer(Correlation(\"total_votes\", \"helpful_votes\")) \\\n",
    "                    .useRepository(repository) \\\n",
    "                    .saveOrAppendResult(resultKey_2) \\\n",
    "                    .run()\n",
    "\n",
    "analysisResult_2_df = AnalyzerContext.successMetricsAsDataFrame(spark, analysisResult_2)\n",
    "analysisResult_2_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we should see two different tags when we load it back from Metrics Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------------------+-------------------+--------------------+-------------+-----------+\n",
      "|entity     |instance                 |name               |value               |dataset_date |tag        |\n",
      "+-----------+-------------------------+-------------------+--------------------+-------------+-----------+\n",
      "|Column     |review_id                |Completeness       |1.0                 |1595457441235|electronics|\n",
      "|Column     |review_id                |ApproxCountDistinct|3010972.0           |1595457441235|electronics|\n",
      "|Mutlicolumn|total_votes,star_rating  |Correlation        |-0.03451097996538765|1595457441235|electronics|\n",
      "|Dataset    |*                        |Size               |3120938.0           |1595457441235|electronics|\n",
      "|Column     |star_rating              |Mean               |4.036143941340712   |1595457441235|electronics|\n",
      "|Column     |top star_rating          |Compliance         |0.7494070692849394  |1595457441235|electronics|\n",
      "|Mutlicolumn|total_votes,helpful_votes|Correlation        |0.9936463809903863  |1595457441235|electronics|\n",
      "|Column     |review_id                |Completeness       |1.0                 |1595457494596|books      |\n",
      "|Column     |review_id                |ApproxCountDistinct|2.005151E7          |1595457494596|books      |\n",
      "|Mutlicolumn|total_votes,star_rating  |Correlation        |-0.13092955077624202|1595457494596|books      |\n",
      "|Dataset    |*                        |Size               |2.072616E7          |1595457494596|books      |\n",
      "|Column     |star_rating              |Mean               |4.340540167594962   |1595457494596|books      |\n",
      "|Column     |top star_rating          |Compliance         |0.8302768095971468  |1595457494596|books      |\n",
      "|Mutlicolumn|total_votes,helpful_votes|Correlation        |0.9613189372804929  |1595457494596|books      |\n",
      "+-----------+-------------------------+-------------------+--------------------+-------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "analysisResult_metRep_2 = repository.load() \\\n",
    "                            .before(ResultKey.current_milli_time()) \\\n",
    "                            .getSuccessMetricsAsDataFrame()\n",
    "\n",
    "analysisResult_metRep_2.show(analysisResult_metRep_2.count(), False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can see the differences in the `dataset_date` and `tag` column and filter our results like so"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------------------+-------------------+--------------------+-------------+-----+\n",
      "|entity     |instance                 |name               |value               |dataset_date |tag  |\n",
      "+-----------+-------------------------+-------------------+--------------------+-------------+-----+\n",
      "|Column     |review_id                |Completeness       |1.0                 |1595457494596|books|\n",
      "|Column     |review_id                |ApproxCountDistinct|2.005151E7          |1595457494596|books|\n",
      "|Mutlicolumn|total_votes,star_rating  |Correlation        |-0.13092955077624202|1595457494596|books|\n",
      "|Dataset    |*                        |Size               |2.072616E7          |1595457494596|books|\n",
      "|Column     |star_rating              |Mean               |4.340540167594962   |1595457494596|books|\n",
      "|Column     |top star_rating          |Compliance         |0.8302768095971468  |1595457494596|books|\n",
      "|Mutlicolumn|total_votes,helpful_votes|Correlation        |0.9613189372804929  |1595457494596|books|\n",
      "+-----------+-------------------------+-------------------+--------------------+-------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filtered_tags = repository.load() \\\n",
    "        .withTagValues(key_tags_2) \\\n",
    "        .getSuccessMetricsAsDataFrame()\n",
    "\n",
    "filtered_tags.show(filtered_tags.count(), False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------------------+-------------------+--------------------+-------------+-----+\n",
      "|entity     |instance                 |name               |value               |dataset_date |tag  |\n",
      "+-----------+-------------------------+-------------------+--------------------+-------------+-----+\n",
      "|Column     |review_id                |Completeness       |1.0                 |1595457494596|books|\n",
      "|Column     |review_id                |ApproxCountDistinct|2.005151E7          |1595457494596|books|\n",
      "|Mutlicolumn|total_votes,star_rating  |Correlation        |-0.13092955077624202|1595457494596|books|\n",
      "|Dataset    |*                        |Size               |2.072616E7          |1595457494596|books|\n",
      "|Column     |star_rating              |Mean               |4.340540167594962   |1595457494596|books|\n",
      "|Column     |top star_rating          |Compliance         |0.8302768095971468  |1595457494596|books|\n",
      "|Mutlicolumn|total_votes,helpful_votes|Correlation        |0.9613189372804929  |1595457494596|books|\n",
      "+-----------+-------------------------+-------------------+--------------------+-------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filtered_time = repository.load() \\\n",
    "        .after(1595457441235+1) \\\n",
    "        .getSuccessMetricsAsDataFrame()\n",
    "\n",
    "filtered_time.show(filtered_time.count(), False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For more info ... look at full list of Metrics Repository in `docs/repository.md` "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
