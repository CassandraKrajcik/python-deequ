{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KLL Checks Example\n",
    "\n",
    "Here is a basic example of running a `Check` with a [KLL Sketches](https://arxiv.org/abs/1603.05346). A sketch serves to represent the larger dataset at hand in a binned statistical representation. KLL Sketches are great because itâ€™s a very compact quantile sketch with a lazy compaction scheme that still remains highly accurate. Furthermore, it's designed to work on streams of data (regardless of completeness) and not just when the entire dataset is static and known. \n",
    "\n",
    "We'll start by creating a Spark session and a small sample dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydeequ\n",
    "\n",
    "import sagemaker_pyspark\n",
    "from pyspark.sql import SparkSession, Row\n",
    "\n",
    "classpath = \":\".join(sagemaker_pyspark.classpath_jars()) # aws-specific jars\n",
    "\n",
    "spark = (SparkSession\n",
    "    .builder\n",
    "    .config(\"spark.driver.extraClassPath\", classpath)\n",
    "    .config(\"spark.jars.packages\", pydeequ.deequ_maven_coord)\n",
    "    .config(\"spark.jars.excludes\", pydeequ.f2j_maven_coord)\n",
    "    .getOrCreate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.sparkContext.parallelize([\n",
    "    Row(idx=1, name=\"Thingy A\", description=\"awesome thing.\", rating=\"high\", numViews=0),\n",
    "    Row(idx=2, name=\"Thingy B\", description=\"available at http://thingb.com\", rating=None, numViews=0),\n",
    "    Row(idx=3, name=None, description=None, rating=\"low\", numViews=5),\n",
    "    Row(idx=4, name=\"Thingy D\", description=\"checkout https://thingd.ca\", rating=\"low\", numViews=10),\n",
    "    Row(idx=5, name=\"Thingy E\", description=None, rating=\"high\", numViews=12)]).toDF()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's construct the Verification runner for our KLL check! \n",
    "\n",
    "`hasSize` and `hasMax` are basic `Checks` that we've already covered in the [basic_example notebook](./basic_example.ipynb), so let's focus our attention on the `kllSketchSatisfies` constraint. Here, we are checking if our KLL sketch size is larger than 3. \n",
    "\n",
    "**However**, we're purposely passing in a KLL Parameter into the constraint saying that our sketch size is 2. So we should expect this to fail!\n",
    "\n",
    "```KLLParameters( spark_session, sketch_size, shrinking_factor, n_buckets) ```\n",
    "\n",
    "Below, you can see the 2 ways you can define the assertion to check for the shrinking factor and sketch size with the `kllSketchSatisfies` check. When you `apply(0)` you get the shrinking factor. When you `apply(1)` you get the sketch_size. \n",
    "\n",
    "```\n",
    "x.parameters().apply(0) => shrinking_factor \n",
    "x.parameters().apply(1) => sketch_size \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydeequ.checks import *\n",
    "from pydeequ.analyzers import KLLParameters\n",
    "from pydeequ.verification import *\n",
    "\n",
    "check = Check(spark, CheckLevel.Error, \"KLL Checks\")\n",
    "\n",
    "result = VerificationSuite(spark) \\\n",
    "    .onData(df) \\\n",
    "    .addCheck(\n",
    "        check.hasSize(lambda x: x == 5) \\\n",
    "        .hasMax(\"numViews\", lambda x: x <= 10) \\\n",
    "        .kllSketchSatisfies(\"numViews\", lambda x: x.parameters().apply(1) >= 3, \n",
    "                           KLLParameters(spark, 2, 0.64, 2))) \\\n",
    "    .run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We found errors in the data, the following constraints were not satisfied:\n",
      "\tMaximumConstraint(Maximum(numViews,None)) failed because: Value: 12.0 does not meet the constraint requirement!\n",
      "\tkllSketchConstraint(KLLSketch(numViews,Some(KLLParameters(2,0.64,2)))) failed because: Value: BucketDistribution(List(BucketValue(0.0,6.0,3), BucketValue(6.0,12.0,2)),List(0.64, 2.0),[[D@4e4e48bd) does not meet the constraint requirement!\n"
     ]
    }
   ],
   "source": [
    "if result.status == \"Success\": \n",
    "    print('The data passed the test, everything is fine!')\n",
    "\n",
    "else:\n",
    "    print('We found errors in the data, the following constraints were not satisfied:')\n",
    "    \n",
    "    for check_json in result.checkResults:\n",
    "        if check_json['constraint_status'] != \"Success\": \n",
    "            print(f\"\\t{check_json['constraint']} failed because: {check_json['constraint_message']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's run it again without specifying the sketch size... \n",
    "\n",
    "When our datasets get bigger, we won't want to limit our sketch to 2 buckets. What happens if we just run with the default values for KLL Sketches? \n",
    "\n",
    "Let's naively check for the `shrinking_factor` to be 0 to fail the check so we can see its output! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "check = Check(spark, CheckLevel.Error, \"KLL Checks\")\n",
    "\n",
    "result = VerificationSuite(spark) \\\n",
    "    .onData(df) \\\n",
    "    .addCheck(\n",
    "        check.hasSize(lambda x: x == 5) \\\n",
    "        .hasMax(\"numViews\", lambda x: x <= 10) \\\n",
    "        .kllSketchSatisfies(\"numViews\", lambda x: x.parameters().apply(0) <= 0)) \\\n",
    "    .run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We found errors in the data, the following constraints were not satisfied:\n",
      "\tMaximumConstraint(Maximum(numViews,None)) failed because: Value: 12.0 does not meet the constraint requirement!\n",
      "\tkllSketchConstraint(KLLSketch(numViews,None)) failed because: Value: BucketDistribution(List(BucketValue(0.0,0.12,2), BucketValue(0.12,0.24,0), BucketValue(0.24,0.36,0), BucketValue(0.36,0.48,0), BucketValue(0.48,0.6,0), BucketValue(0.6,0.72,0), BucketValue(0.72,0.84,0), BucketValue(0.84,0.96,0), BucketValue(0.96,1.08,0), BucketValue(1.08,1.2,0), BucketValue(1.2,1.32,0), BucketValue(1.32,1.44,0), BucketValue(1.44,1.56,0), BucketValue(1.56,1.68,0), BucketValue(1.68,1.8,0), BucketValue(1.8,1.92,0), BucketValue(1.92,2.04,0), BucketValue(2.04,2.16,0), BucketValue(2.16,2.28,0), BucketValue(2.28,2.4,0), BucketValue(2.4,2.52,0), BucketValue(2.52,2.64,0), BucketValue(2.64,2.76,0), BucketValue(2.76,2.88,0), BucketValue(2.88,3.0,0), BucketValue(3.0,3.12,0), BucketValue(3.12,3.24,0), BucketValue(3.24,3.36,0), BucketValue(3.36,3.48,0), BucketValue(3.48,3.6,0), BucketValue(3.6,3.72,0), BucketValue(3.72,3.84,0), BucketValue(3.84,3.96,0), BucketValue(3.96,4.08,0), BucketValue(4.08,4.2,0), BucketValue(4.2,4.32,0), BucketValue(4.32,4.44,0), BucketValue(4.44,4.56,0), BucketValue(4.56,4.68,0), BucketValue(4.68,4.8,0), BucketValue(4.8,4.92,0), BucketValue(4.92,5.04,1), BucketValue(5.04,5.16,0), BucketValue(5.16,5.28,0), BucketValue(5.28,5.4,0), BucketValue(5.4,5.52,0), BucketValue(5.52,5.64,0), BucketValue(5.64,5.76,0), BucketValue(5.76,5.88,0), BucketValue(5.88,6.0,0), BucketValue(6.0,6.12,0), BucketValue(6.12,6.24,0), BucketValue(6.24,6.36,0), BucketValue(6.36,6.48,0), BucketValue(6.48,6.6,0), BucketValue(6.6,6.72,0), BucketValue(6.72,6.84,0), BucketValue(6.84,6.96,0), BucketValue(6.96,7.08,0), BucketValue(7.08,7.2,0), BucketValue(7.2,7.32,0), BucketValue(7.32,7.44,0), BucketValue(7.44,7.56,0), BucketValue(7.56,7.68,0), BucketValue(7.68,7.8,0), BucketValue(7.8,7.92,0), BucketValue(7.92,8.04,0), BucketValue(8.04,8.16,0), BucketValue(8.16,8.28,0), BucketValue(8.28,8.4,0), BucketValue(8.4,8.52,0), BucketValue(8.52,8.64,0), BucketValue(8.64,8.76,0), BucketValue(8.76,8.88,0), BucketValue(8.88,9.0,0), BucketValue(9.0,9.12,0), BucketValue(9.12,9.24,0), BucketValue(9.24,9.36,0), BucketValue(9.36,9.48,0), BucketValue(9.48,9.6,0), BucketValue(9.6,9.72,0), BucketValue(9.72,9.84,0), BucketValue(9.84,9.96,0), BucketValue(9.96,10.08,1), BucketValue(10.08,10.2,0), BucketValue(10.2,10.32,0), BucketValue(10.32,10.44,0), BucketValue(10.44,10.56,0), BucketValue(10.56,10.68,0), BucketValue(10.68,10.8,0), BucketValue(10.8,10.92,0), BucketValue(10.92,11.04,0), BucketValue(11.04,11.16,0), BucketValue(11.16,11.28,0), BucketValue(11.28,11.4,0), BucketValue(11.4,11.52,0), BucketValue(11.52,11.64,0), BucketValue(11.64,11.76,0), BucketValue(11.76,11.88,0), BucketValue(11.88,12.0,1)),List(0.64, 2048.0),[[D@2126ca35) does not meet the constraint requirement!\n"
     ]
    }
   ],
   "source": [
    "if result.status == \"Success\": \n",
    "    print('The data passed the test, everything is fine!')\n",
    "\n",
    "else:\n",
    "    print('We found errors in the data, the following constraints were not satisfied:')\n",
    "    \n",
    "    for check_json in result.checkResults:\n",
    "        if check_json['constraint_status'] != \"Success\": \n",
    "            print(f\"\\t{check_json['constraint']} failed because: {check_json['constraint_message']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we've uncovered PyDeequ's default parameters for KLL Sketches!\n",
    "\n",
    "The output above displays 100 buckets that the KLL sketch outputted with the following sketch size and shrinking factor. \n",
    "\n",
    "```\n",
    "DEFAULT_SKETCH_SIZE = 2048\n",
    "DEFAULT_SHRINKING_FACTOR = 0.64\n",
    "MAXIMUM_ALLOWED_DETAIL_BINS = 100\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
